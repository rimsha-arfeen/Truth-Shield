# -*- coding: utf-8 -*-
"""TRUTHSHIELD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G5iBd7Qu4hLhwKnT9Oz90rBtp5dxtH-U
"""

GOOGLE_API_KEY = "AIzaSyBzxYkuZTf2t5iQULXRVn71k-8QHFUgDtQ"
EMAIL_API = "https://emailrep.io/"
NUMVERIFY_API_KEY = "e43678c70cc99b8312c41a9e18b9070f"

!pip install gradio

import re
import nltk
import pandas as pd
import requests
import gradio as gr
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from bs4 import BeautifulSoup

# Load dataset
dataset_url = "https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms-spam-collection/spam.csv"
nltk.download('stopwords')

try:
    df = pd.read_csv(dataset_url, encoding="latin-1")
    df = df[['v1', 'v2']]
    df.columns = ['label', 'message']
    df['label'] = df['label'].map({'ham': 0, 'spam': 1})
except Exception as e:
    print(f"Error loading dataset: {e}")
    df = pd.DataFrame({
        'message': ["Free lottery win! Claim now!", "Hey, how are you?", "Get cheap meds now!"],
        'label': [1, 0, 1]
    })

# Train spam classifier
pipeline = Pipeline([
    ('vectorizer', CountVectorizer(stop_words=stopwords.words('english'))),
    ('classifier', MultinomialNB())
])
pipeline.fit(df['message'], df['label'])

def is_spam(message):
    prediction = pipeline.predict([message])
    return 'SPAM' if prediction[0] == 1 else 'NOT SPAM'

def fact_check_google(query):
    """Check for misinformation using Google Fact Check API"""
    api_key = "AIzaSyBzxYkuZTf2t5iQULXRVn71k-8QHFUgDtQ"  # Replace with your actual API key
    url = f"https://factchecktools.googleapis.com/v1alpha1/claims:search?query={query}&key={api_key}"

    try:
        response = requests.get(url)
        if response.status_code == 200:
            result = response.json()
            if 'claims' in result and result['claims']:
                return result['claims'][0]['textualRating']
        return "No fact check results found."
    except Exception as e:
        return f"Error: {e}"

def verify_source(email, phone):
    """Verify email and phone number authenticity"""
    email_status = "Unverified"
    phone_status = "Unverified"

    if email:
        try:
            email_response = requests.get(f"https://emailrep.io/{email}")
            if email_response.status_code == 200:
                email_status = "Verified"
        except:
            email_status = "Verification Failed"

    if phone:
        try:
            numverify_api_key = "e43678c70cc99b8312c41a9e18b9070f"  # Replace with your actual API key
            phone_response = requests.get(f"http://apilayer.net/api/validate?access_key={numverify_api_key}&number={phone}")
            if phone_response.status_code == 200:
                phone_status = "Verified"
        except:
            phone_status = "Verification Failed"

    return f"Email: {email_status}, Phone: {phone_status}"

def highlight_misinformation(text):
    """Highlight words that may indicate misinformation"""
    keywords = ["fraud", "scam", "alert", "myth", "false", "misleading", "warning", "hoax", "fake", "rumor", "unverified"]
    pattern = r"\b(" + "|".join(keywords) + r")\b"

    highlighted_text = re.sub(pattern, lambda x: x.group(1).upper(), text, flags=re.IGNORECASE)
    return highlighted_text

def get_related_content(query):
    """Fetch related content from DuckDuckGo search without links"""
    search_query = f"{query} scam fraud alert"
    url = f"https://html.duckduckgo.com/html/?q={search_query}"

    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            results = soup.find_all("a", class_="result__a", limit=5)

            related_content = [highlight_misinformation(result.text.strip()) for result in results]

            return related_content if related_content else ["No relevant related content found."]
    except Exception as e:
        return [f"Error fetching related content: {e}"]

def analyze_text(message, email, phone):
    """Main function to analyze message"""
    spam_result = is_spam(message)
    fact_check_result = fact_check_google(message)
    verification_result = verify_source(email, phone)
    related_content = get_related_content(message)

    return spam_result, verification_result, fact_check_result, "\n".join(related_content)

# Create Gradio UI
iface = gr.Interface(
    fn=analyze_text,
    inputs=[
        gr.Textbox(label="Enter message"),
        gr.Textbox(label="Enter email (optional)"),
        gr.Textbox(label="Enter phone number (optional)")
    ],
    outputs=[
        gr.Textbox(label="Spam Detection"),
        gr.Textbox(label="Source Verification"),
        gr.Textbox(label="Fact Check Result"),
        gr.Textbox(label="Related Content", lines=5)
    ],
    title="üîç Truth Shield - Spam & Misinformation Detector",
    description="Enter a message, email, or phone number to check for spam, fact-check, and verify sources."
)

iface.launch(share=True)

!ls

!curl ifconfig.me

